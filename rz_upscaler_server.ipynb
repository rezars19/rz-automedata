{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RZ Automedata - Media Upscale Server\n",
    "### Real-ESRGAN on Google Colab GPU\n",
    "\n",
    "### Setup:\n",
    "1. **GPU Runtime**: `Runtime` > `Change runtime type` > `T4 GPU`\n",
    "2. **Run All**: `Ctrl+F9`\n",
    "3. Done! Watches Google Drive for jobs automatically.\n",
    "\n",
    "**Supports both Video + Image upscaling!**\n",
    "\n",
    "**No ngrok. No URL. Just run and go!**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 1. Install Dependencies\n",
    "\n",
    "import subprocess, os, shutil\n",
    "\n",
    "# --- GPU Check ---\n",
    "try:\n",
    "    r = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv,noheader'],\n",
    "                       capture_output=True, text=True, timeout=10)\n",
    "    if r.returncode == 0:\n",
    "        print(f'[OK] GPU: {r.stdout.strip()}')\n",
    "    else:\n",
    "        print('[WARNING] No GPU! Go to Runtime > Change runtime type > T4 GPU')\n",
    "except FileNotFoundError:\n",
    "    print('[WARNING] nvidia-smi not found! No GPU.')\n",
    "except Exception as e:\n",
    "    print(f'[WARNING] GPU check error: {e}')\n",
    "\n",
    "# --- FFmpeg ---\n",
    "!apt-get update -qq && apt-get install -y -qq ffmpeg > /dev/null 2>&1\n",
    "print('[OK] FFmpeg')\n",
    "\n",
    "# --- Real-ESRGAN ---\n",
    "if not os.path.exists('/content/Real-ESRGAN'):\n",
    "    !git clone https://github.com/xinntao/Real-ESRGAN.git /content/Real-ESRGAN\n",
    "\n",
    "%cd /content/Real-ESRGAN\n",
    "\n",
    "!pip install -q basicsr facexlib gfpgan\n",
    "!pip install -q -r requirements.txt\n",
    "!python setup.py develop > /dev/null 2>&1\n",
    "\n",
    "# --- Patch torchvision ---\n",
    "def patch_basicsr_torchvision():\n",
    "    import importlib\n",
    "    spec = importlib.util.find_spec('basicsr')\n",
    "    if spec is None or spec.origin is None:\n",
    "        print('[WARNING] basicsr not found'); return\n",
    "    basicsr_dir = os.path.dirname(spec.origin)\n",
    "    deg_file = os.path.join(basicsr_dir, 'data', 'degradations.py')\n",
    "    if not os.path.exists(deg_file): return\n",
    "    with open(deg_file, 'r') as f: code = f.read()\n",
    "    if 'functional_tensor' in code:\n",
    "        code = code.replace(\n",
    "            'from torchvision.transforms.functional_tensor import rgb_to_grayscale',\n",
    "            'from torchvision.transforms.functional import rgb_to_grayscale')\n",
    "        with open(deg_file, 'w') as f: f.write(code)\n",
    "        print('[FIX] Patched basicsr (functional_tensor -> functional)')\n",
    "    else:\n",
    "        print('[OK] basicsr already patched')\n",
    "\n",
    "patch_basicsr_torchvision()\n",
    "import basicsr\n",
    "print('[OK] basicsr imported')\n",
    "\n",
    "# --- Patch torch.load for PyTorch 2.6+ compatibility ---\n",
    "import torch\n",
    "_orig_torch_load = torch.load\n",
    "def _patched_load(*args, **kwargs):\n",
    "    kwargs.setdefault(\"weights_only\", False)\n",
    "    return _orig_torch_load(*args, **kwargs)\n",
    "torch.load = _patched_load\n",
    "print(\"[OK] torch.load patched for PyTorch 2.6+\")\n",
    "\n",
    "# --- Download models ---\n",
    "models_dir = '/content/Real-ESRGAN/weights'\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "model_urls = {\n",
    "    'RealESRGAN_x4plus.pth': 'https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth',\n",
    "    'RealESRGAN_x4plus_anime_6B.pth': 'https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.2.4/RealESRGAN_x4plus_anime_6B.pth',\n",
    "    'realesr-animevideov3.pth': 'https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.5.0/realesr-animevideov3.pth',\n",
    "    'GFPGANv1.3.pth': 'https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth'\n",
    "}\n",
    "for name, url in model_urls.items():\n",
    "    path = os.path.join(models_dir, name)\n",
    "    if not os.path.exists(path):\n",
    "        !wget -q {url} -O {path}\n",
    "        print(f'[OK] Downloaded {name}')\n",
    "    else:\n",
    "        print(f'[OK] {name} exists')\n",
    "\n",
    "exp_dir = '/content/Real-ESRGAN/experiments/pretrained_models'\n",
    "os.makedirs(exp_dir, exist_ok=True)\n",
    "for name in model_urls:\n",
    "    src = os.path.join(models_dir, name)\n",
    "    dst = os.path.join(exp_dir, name)\n",
    "    if os.path.exists(src) and not os.path.exists(dst):\n",
    "        os.symlink(src, dst)\n",
    "\n",
    "print('[OK] All models ready')\n",
    "\n",
    "result = subprocess.run(\n",
    "    ['python', '/content/Real-ESRGAN/inference_realesrgan.py', '--help'],\n",
    "    capture_output=True, text=True, cwd='/content/Real-ESRGAN')\n",
    "if result.returncode == 0:\n",
    "    print('[OK] Real-ESRGAN verification PASSED!')\n",
    "else:\n",
    "    print('[FAILED] verification failed')\n",
    "    print(result.stderr[-500:])\n",
    "\n",
    "print('\\nAll dependencies ready!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 2. Mount Google Drive\n",
    "\n",
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "DRIVE_BASE   = '/content/drive/MyDrive/RZ_Upscaler'\n",
    "DRIVE_INPUT  = os.path.join(DRIVE_BASE, 'Input')\n",
    "DRIVE_OUTPUT = os.path.join(DRIVE_BASE, 'Output')\n",
    "DRIVE_JOBS   = os.path.join(DRIVE_BASE, 'Jobs')\n",
    "DRIVE_STATUS = os.path.join(DRIVE_BASE, 'Status')\n",
    "\n",
    "for d in [DRIVE_INPUT, DRIVE_OUTPUT, DRIVE_JOBS, DRIVE_STATUS]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "print('[OK] Google Drive mounted')\n",
    "print(f'Input:  {DRIVE_INPUT}')\n",
    "print(f'Output: {DRIVE_OUTPUT}')\n",
    "print(f'Jobs:   {DRIVE_JOBS}')\n",
    "print(f'Status: {DRIVE_STATUS}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 3. Start Job Watcher\n",
    "# @markdown Watches Google Drive Jobs/ folder for new jobs.\n",
    "# @markdown **No ngrok needed!** All communication through Google Drive.\n",
    "# @markdown **Supports Video + Image upscaling!**\n",
    "\n",
    "import os, re, glob, shutil, subprocess, json, time, threading, traceback\n",
    "\n",
    "DRIVE_BASE   = '/content/drive/MyDrive/RZ_Upscaler'\n",
    "DRIVE_INPUT  = os.path.join(DRIVE_BASE, 'Input')\n",
    "DRIVE_OUTPUT = os.path.join(DRIVE_BASE, 'Output')\n",
    "DRIVE_JOBS   = os.path.join(DRIVE_BASE, 'Jobs')\n",
    "DRIVE_STATUS = os.path.join(DRIVE_BASE, 'Status')\n",
    "ESRGAN_DIR   = '/content/Real-ESRGAN'\n",
    "\n",
    "# Image file extensions\n",
    "IMAGE_EXTS = {'.png', '.jpg', '.jpeg', '.bmp', '.tiff', '.tif', '.webp'}\n",
    "\n",
    "# NVENC H.264 max resolution per dimension\n",
    "NVENC_MAX_DIM = 4096\n",
    "\n",
    "processed_jobs = set()\n",
    "\n",
    "def is_image_file(filename):\n",
    "    return os.path.splitext(filename)[1].lower() in IMAGE_EXTS\n",
    "\n",
    "def get_gpu_info():\n",
    "    try:\n",
    "        r = subprocess.run(\n",
    "            ['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv,noheader'],\n",
    "            capture_output=True, text=True, timeout=5)\n",
    "        if r.returncode == 0:\n",
    "            parts = r.stdout.strip().split(',')\n",
    "            return {'name': parts[0].strip(), 'memory': parts[1].strip() if len(parts) > 1 else ''}\n",
    "    except: pass\n",
    "    return {'name': 'Unknown', 'memory': ''}\n",
    "\n",
    "GPU_INFO = get_gpu_info()\n",
    "print(f'GPU: {GPU_INFO[\"name\"]} ({GPU_INFO[\"memory\"]})')\n",
    "\n",
    "\n",
    "# =============================================\n",
    "# STATUS + LOG\n",
    "# =============================================\n",
    "\n",
    "task_logs = {}\n",
    "\n",
    "def log(task_id, msg):\n",
    "    \"\"\"Add log line and print.\"\"\"\n",
    "    if task_id not in task_logs:\n",
    "        task_logs[task_id] = []\n",
    "    task_logs[task_id].append(msg)\n",
    "    print(f'  {msg}')\n",
    "\n",
    "def update_status(task_id, status, progress=0, stage='', error=None):\n",
    "    \"\"\"Write status + full log to Drive Status/ folder.\"\"\"\n",
    "    data = {\n",
    "        'task_id': task_id,\n",
    "        'status': status,\n",
    "        'progress': progress,\n",
    "        'stage': stage,\n",
    "        'error': error,\n",
    "        'gpu': GPU_INFO['name'],\n",
    "        'log': task_logs.get(task_id, []),\n",
    "        'updated_at': time.time(),\n",
    "    }\n",
    "    status_path = os.path.join(DRIVE_STATUS, f'{task_id}.json')\n",
    "    try:\n",
    "        tmp = status_path + '.tmp'\n",
    "        with open(tmp, 'w') as f:\n",
    "            json.dump(data, f)\n",
    "        os.replace(tmp, status_path)\n",
    "    except:\n",
    "        try:\n",
    "            with open(status_path, 'w') as f:\n",
    "                json.dump(data, f)\n",
    "        except: pass\n",
    "\n",
    "\n",
    "# =============================================\n",
    "# FRAME COUNTER (for video)\n",
    "# =============================================\n",
    "\n",
    "_upscale_running = False\n",
    "\n",
    "def _count_output_frames(frames_out, total_frames, task_id):\n",
    "    global _upscale_running\n",
    "    while _upscale_running:\n",
    "        try:\n",
    "            done = len(glob.glob(os.path.join(frames_out, '*.png')))\n",
    "            if total_frames > 0 and done > 0:\n",
    "                pct = min(12 + int((done / total_frames) * 63), 75)\n",
    "                msg = f'[progress] {done}/{total_frames} ({pct}%)'\n",
    "                # Replace previous progress line\n",
    "                logs = task_logs.get(task_id, [])\n",
    "                task_logs[task_id] = [l for l in logs if not l.startswith('[progress]')]\n",
    "                task_logs[task_id].append(msg)\n",
    "                update_status(task_id, 'processing', pct, f'Upscaling frame {done}/{total_frames}')\n",
    "                print(f'  {msg}')\n",
    "        except: pass\n",
    "        time.sleep(3)\n",
    "\n",
    "\n",
    "# =============================================\n",
    "# ENCODER SELECTION HELPER\n",
    "# =============================================\n",
    "\n",
    "def select_encoder(out_w, out_h):\n",
    "    \"\"\"Select best encoder. Falls back to libx264 if resolution exceeds NVENC limit.\n",
    "    Returns (encoder_args_list, encoder_label).\n",
    "    \"\"\"\n",
    "    exceeds_limit = out_w > NVENC_MAX_DIM or out_h > NVENC_MAX_DIM\n",
    "\n",
    "    hw_encoder = None\n",
    "    encoder_label = 'libx264 (CPU)'\n",
    "\n",
    "    if not exceeds_limit:\n",
    "        try:\n",
    "            enc_check = subprocess.run(['ffmpeg', '-hide_banner', '-encoders'],\n",
    "                capture_output=True, text=True, timeout=5)\n",
    "            for enc_name, enc_lbl in [('h264_nvenc','NVENC (NVIDIA)'),('h264_amf','AMF (AMD)'),('h264_qsv','QSV (Intel)')]:\n",
    "                if enc_name in enc_check.stdout:\n",
    "                    hw_encoder = enc_name\n",
    "                    encoder_label = enc_lbl\n",
    "                    break\n",
    "        except: pass\n",
    "    else:\n",
    "        print(f'  [INFO] Output {out_w}x{out_h} exceeds NVENC limit ({NVENC_MAX_DIM}), using libx264')\n",
    "\n",
    "    # Build encoder args — always use 50M bitrate for consistent quality\n",
    "    if hw_encoder:\n",
    "        if hw_encoder == 'h264_nvenc': preset_args = ['-preset', 'p1']\n",
    "        elif hw_encoder == 'h264_amf': preset_args = ['-quality', 'speed']\n",
    "        else: preset_args = ['-preset', 'veryfast']\n",
    "        enc_args = ['-c:v', hw_encoder] + preset_args + [\n",
    "            '-b:v', '50M', '-maxrate', '55M', '-bufsize', '100M', '-pix_fmt', 'yuv420p'\n",
    "        ]\n",
    "    else:\n",
    "        enc_args = [\n",
    "            '-c:v', 'libx264', '-b:v', '50M', '-maxrate', '55M',\n",
    "            '-bufsize', '100M', '-preset', 'ultrafast', '-pix_fmt', 'yuv420p'\n",
    "        ]\n",
    "\n",
    "    return enc_args, encoder_label\n",
    "\n",
    "\n",
    "# =============================================\n",
    "# IMAGE PROCESSOR (direct upscale, no frames)\n",
    "# =============================================\n",
    "\n",
    "def process_image(job):\n",
    "    \"\"\"Process a single image — direct upscale, no frame extraction.\"\"\"\n",
    "    task_id = job['task_id']\n",
    "    filename = job['filename']\n",
    "    scale = job.get('scale', 4)\n",
    "    model = job.get('model', 'realesr-animevideov3')\n",
    "    face_enhance = job.get('face_enhance', False)\n",
    "    output_format = job.get('output_format', 'png')\n",
    "    target_fps = job.get('target_fps', 30)\n",
    "\n",
    "    input_path = os.path.join(DRIVE_INPUT, filename)\n",
    "    work_dir = f'/content/work_{task_id}'\n",
    "    os.makedirs(work_dir, exist_ok=True)\n",
    "\n",
    "    task_logs[task_id] = []\n",
    "    log(task_id, f'Job: {filename} (IMAGE)')\n",
    "    log(task_id, f'Model: {model} | Scale: {scale}x | GPU: {GPU_INFO[\"name\"]}')\n",
    "\n",
    "    try:\n",
    "        # === WAIT FOR FILE ===\n",
    "        update_status(task_id, 'waiting', 0, 'Waiting for image file...')\n",
    "        t0 = time.time()\n",
    "        while not os.path.exists(input_path):\n",
    "            if time.time() - t0 > 600:\n",
    "                raise Exception('File not found after 10 min')\n",
    "            time.sleep(3)\n",
    "\n",
    "        log(task_id, 'File found, verifying sync...')\n",
    "        prev, stable = -1, 0\n",
    "        while stable < 2:\n",
    "            sz = os.path.getsize(input_path) if os.path.exists(input_path) else 0\n",
    "            if sz > 0 and sz == prev: stable += 1\n",
    "            else: stable = 0\n",
    "            prev = sz\n",
    "            time.sleep(2)\n",
    "\n",
    "        mb = os.path.getsize(input_path) / (1024*1024)\n",
    "        log(task_id, f'\\u2713 Image ready: {mb:.1f} MB')\n",
    "        update_status(task_id, 'processing', 5, 'Starting image upscale...')\n",
    "\n",
    "        # === UPSCALE IMAGE DIRECTLY ===\n",
    "        log(task_id, f'\\u25b6 UPSCALING IMAGE ({scale}x with {model})')\n",
    "        update_status(task_id, 'processing', 10, f'Upscaling image ({scale}x)...')\n",
    "\n",
    "        out_dir = os.path.join(work_dir, 'output')\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "        cmd = [\n",
    "            'python', os.path.join(ESRGAN_DIR, 'inference_realesrgan.py'),\n",
    "            '-i', input_path, '-o', out_dir,\n",
    "            '-n', model, '-s', str(scale),\n",
    "            '--suffix', 'out', '--ext', output_format\n",
    "        ]\n",
    "        if 'x4plus' in model:\n",
    "            cmd.extend(['--tile', '800'])\n",
    "        if face_enhance:\n",
    "            cmd.append('--face_enhance')\n",
    "\n",
    "        t1 = time.time()\n",
    "        update_status(task_id, 'processing', 20, 'Upscaling image on GPU...')\n",
    "\n",
    "        proc = subprocess.Popen(\n",
    "            cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT,\n",
    "            universal_newlines=True, bufsize=1, cwd=ESRGAN_DIR)\n",
    "\n",
    "        output_lines = []\n",
    "        for line in iter(proc.stdout.readline, ''):\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                output_lines.append(line)\n",
    "                task_logs[task_id].append(f'> {line}')\n",
    "                print(f'  > {line}')\n",
    "                update_status(task_id, 'processing', 50, 'Upscaling image on GPU...')\n",
    "        proc.wait()\n",
    "        upscale_time = time.time() - t1\n",
    "\n",
    "        if proc.returncode != 0:\n",
    "            err = '\\n'.join(output_lines[-10:])\n",
    "            raise Exception(f'ESRGAN failed: {err[:300]}')\n",
    "\n",
    "        # Find output file\n",
    "        out_files = glob.glob(os.path.join(out_dir, f'*_out.{output_format}'))\n",
    "        if not out_files:\n",
    "            # Try any file in output dir\n",
    "            out_files = glob.glob(os.path.join(out_dir, '*.*'))\n",
    "        if not out_files:\n",
    "            raise Exception('No upscaled image found in output')\n",
    "\n",
    "        upscaled_path = out_files[0]\n",
    "        log(task_id, f'\\u2713 Upscaled in {upscale_time:.1f}s')\n",
    "        update_status(task_id, 'processing', 75, f'Upscaled in {upscale_time:.1f}s')\n",
    "\n",
    "        # === COPY TO DRIVE OUTPUT ===\n",
    "        out_name = f'{task_id}_UPSCALED.{output_format}'\n",
    "        out_path = os.path.join(DRIVE_OUTPUT, out_name)\n",
    "\n",
    "        log(task_id, f'Saving to Drive: {out_name}')\n",
    "        update_status(task_id, 'processing', 85, 'Saving upscaled image to Drive...')\n",
    "        shutil.copy2(upscaled_path, out_path)\n",
    "\n",
    "        out_mb = os.path.getsize(out_path) / (1024*1024)\n",
    "        total_time = time.time() - t0\n",
    "\n",
    "        log(task_id, f'\\u2713 Output: {out_name} ({out_mb:.1f} MB)')\n",
    "        log(task_id, f'\\u2705 DONE in {total_time:.1f}s!')\n",
    "        update_status(task_id, 'completed', 100, f'Complete! ({out_mb:.1f} MB)')\n",
    "        print(f'\\n[DONE] {out_name} ({out_mb:.1f} MB) in {total_time:.1f}s')\n",
    "\n",
    "    except Exception as e:\n",
    "        log(task_id, f'\\u274c ERROR: {str(e)[:150]}')\n",
    "        update_status(task_id, 'failed', 0, f'Error: {str(e)[:150]}', str(e))\n",
    "        print(f'[FAIL] {task_id}: {e}')\n",
    "        traceback.print_exc()\n",
    "    finally:\n",
    "        if os.path.exists(work_dir):\n",
    "            shutil.rmtree(work_dir, ignore_errors=True)\n",
    "        if os.path.exists(input_path):\n",
    "            try: os.remove(input_path)\n",
    "            except: pass\n",
    "        job_path = os.path.join(DRIVE_JOBS, f'{task_id}.json')\n",
    "        try:\n",
    "            if os.path.exists(job_path): os.remove(job_path)\n",
    "        except: pass\n",
    "\n",
    "\n",
    "# =============================================\n",
    "# VIDEO PROCESSOR\n",
    "# =============================================\n",
    "\n",
    "def process_video(job):\n",
    "    global _upscale_running\n",
    "    task_id = job['task_id']\n",
    "    filename = job['filename']\n",
    "    scale = job.get('scale', 4)\n",
    "    model = job.get('model', 'realesr-animevideov3')\n",
    "    face_enhance = job.get('face_enhance', False)\n",
    "    mute_audio = job.get('mute_audio', False)\n",
    "    output_format = job.get('output_format', 'mp4')\n",
    "    target_fps = job.get('target_fps', 30)\n",
    "\n",
    "    input_path = os.path.join(DRIVE_INPUT, filename)\n",
    "    work_dir = f'/content/work_{task_id}'\n",
    "    frames_in = os.path.join(work_dir, 'frames_in')\n",
    "    frames_out = os.path.join(work_dir, 'frames_out')\n",
    "    os.makedirs(frames_in, exist_ok=True)\n",
    "    os.makedirs(frames_out, exist_ok=True)\n",
    "\n",
    "    task_logs[task_id] = []\n",
    "    log(task_id, f'Job: {filename} (VIDEO)')\n",
    "    log(task_id, f'Model: {model} | Scale: {scale}x | GPU: {GPU_INFO[\"name\"]}')\n",
    "\n",
    "    try:\n",
    "        # === WAIT FOR FILE ===\n",
    "        update_status(task_id, 'waiting', 0, 'Waiting for file...')\n",
    "        t0 = time.time()\n",
    "        while not os.path.exists(input_path):\n",
    "            if time.time() - t0 > 600:\n",
    "                raise Exception('File not found after 10 min')\n",
    "            time.sleep(3)\n",
    "\n",
    "        log(task_id, 'File found, verifying sync...')\n",
    "        prev, stable = -1, 0\n",
    "        while stable < 2:\n",
    "            sz = os.path.getsize(input_path) if os.path.exists(input_path) else 0\n",
    "            if sz > 0 and sz == prev: stable += 1\n",
    "            else: stable = 0\n",
    "            prev = sz\n",
    "            time.sleep(2)\n",
    "\n",
    "        mb = os.path.getsize(input_path) / (1024*1024)\n",
    "        log(task_id, f'\\u2713 File ready: {mb:.1f} MB')\n",
    "        update_status(task_id, 'processing', 2, 'Analyzing video...')\n",
    "\n",
    "        # === PHASE 1: EXTRACT FRAMES ===\n",
    "        log(task_id, 'Analyzing video...')\n",
    "        probe = subprocess.run(\n",
    "            ['ffprobe', '-v', 'quiet', '-print_format', 'json',\n",
    "             '-show_streams', '-show_format', input_path],\n",
    "            capture_output=True, text=True)\n",
    "        info = json.loads(probe.stdout)\n",
    "        source_fps = 30.0\n",
    "        has_audio = False\n",
    "        width = 0\n",
    "        height = 0\n",
    "        for s in info.get('streams', []):\n",
    "            if s.get('codec_type') == 'video':\n",
    "                width = int(s.get('width', 0))\n",
    "                height = int(s.get('height', 0))\n",
    "                rf = s.get('r_frame_rate', '30/1')\n",
    "                if '/' in str(rf):\n",
    "                    n, d = str(rf).split('/')\n",
    "                    try: source_fps = float(n)/float(d)\n",
    "                    except: source_fps = 30.0\n",
    "                else:\n",
    "                    try: source_fps = float(rf)\n",
    "                    except: source_fps = 30.0\n",
    "            elif s.get('codec_type') == 'audio':\n",
    "                has_audio = True\n",
    "\n",
    "        # Default source FPS if not detected\n",
    "        # target_fps=0 means 'Original' - keep source FPS\n",
    "        effective_fps = target_fps if target_fps > 0 else int(round(source_fps))\n",
    "        need_interpolation = target_fps > 0 and target_fps > source_fps + 1\n",
    "\n",
    "        # Calculate output resolution\n",
    "        out_w = width * scale\n",
    "        out_h = height * scale\n",
    "\n",
    "        log(task_id, f'\\u2713 Video: {width}x{height} @ {source_fps:.0f} fps')\n",
    "        log(task_id, f'\\u2713 Output: {out_w}x{out_h} ({scale}x)')\n",
    "        if has_audio:\n",
    "            log(task_id, f'\\u2713 Audio: detected{\" (will be muted)\" if mute_audio else \"\"}')\n",
    "\n",
    "        log(task_id, 'Extracting frames...')\n",
    "        update_status(task_id, 'processing', 5, 'Extracting frames...')\n",
    "        t1 = time.time()\n",
    "        r = subprocess.run([\n",
    "            'ffmpeg', '-y', '-threads', '0', '-i', input_path,\n",
    "            '-qscale:v', '1', '-qmin', '1', '-qmax', '1',\n",
    "            os.path.join(frames_in, 'frame_%08d.png')\n",
    "        ], capture_output=True, text=True)\n",
    "        if r.returncode != 0:\n",
    "            raise Exception('Frame extraction failed')\n",
    "        total_frames = len(glob.glob(os.path.join(frames_in, '*.png')))\n",
    "        if total_frames == 0:\n",
    "            raise Exception('No frames extracted')\n",
    "        extract_time = time.time() - t1\n",
    "        log(task_id, f'\\u2713 {total_frames} frames extracted in {extract_time:.1f}s')\n",
    "        update_status(task_id, 'processing', 10, f'{total_frames} frames extracted')\n",
    "\n",
    "        # === PHASE 2: UPSCALE ===\n",
    "        log(task_id, f'\\u25b6 UPSCALING: {width}x{height} -> {out_w}x{out_h} ({scale}x)')\n",
    "        log(task_id, f'  Model: {model}')\n",
    "        update_status(task_id, 'processing', 12, f'Upscaling {total_frames} frames...')\n",
    "        _upscale_running = True\n",
    "\n",
    "        cmd = [\n",
    "            'python', os.path.join(ESRGAN_DIR, 'inference_realesrgan.py'),\n",
    "            '-i', frames_in, '-o', frames_out,\n",
    "            '-n', model, '-s', str(scale),\n",
    "            '--suffix', 'out', '--ext', 'png'\n",
    "        ]\n",
    "        # x4plus uses much more VRAM than animevideov3, tile to avoid OOM\n",
    "        if 'x4plus' in model:\n",
    "            cmd.extend(['--tile', '800'])\n",
    "        if face_enhance: cmd.append('--face_enhance')\n",
    "\n",
    "        t2 = time.time()\n",
    "        counter = threading.Thread(\n",
    "            target=_count_output_frames,\n",
    "            args=(frames_out, total_frames, task_id),\n",
    "            daemon=True)\n",
    "        counter.start()\n",
    "\n",
    "        proc = subprocess.Popen(\n",
    "            cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT,\n",
    "            universal_newlines=True, bufsize=1, cwd=ESRGAN_DIR)\n",
    "\n",
    "        output_lines = []\n",
    "        for line in iter(proc.stdout.readline, ''):\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                output_lines.append(line)\n",
    "                task_logs[task_id].append(f'> {line}')\n",
    "                print(f'  > {line}')\n",
    "        proc.wait()\n",
    "        _upscale_running = False\n",
    "        upscale_time = time.time() - t2\n",
    "\n",
    "        if proc.returncode != 0:\n",
    "            err = '\\n'.join(output_lines[-10:])\n",
    "            raise Exception(f'ESRGAN failed: {err[:300]}')\n",
    "\n",
    "        out_count = len(glob.glob(os.path.join(frames_out, '*.png')))\n",
    "        if out_count == 0:\n",
    "            raise Exception('No upscaled frames')\n",
    "\n",
    "        log(task_id, f'\\u2713 PHASE 2 COMPLETE: Upscaled {out_count} frames in {upscale_time:.1f}s')\n",
    "        update_status(task_id, 'processing', 75, f'Upscaled {out_count} frames')\n",
    "\n",
    "        # === PHASE 3: MERGE TO VIDEO ===\n",
    "        log(task_id, '')\n",
    "        log(task_id, f'\\U0001f39e PHASE 3: MERGING TO VIDEO')\n",
    "        log(task_id, f'  Merging {out_count} frames at {effective_fps} FPS{\" (interpolated)\" if need_interpolation else \"\"}')\n",
    "        update_status(task_id, 'merging', 78, 'Merging frames to video...')\n",
    "\n",
    "        out_name = f'{task_id}_UPSCALED.{output_format}'\n",
    "        out_path = os.path.join(DRIVE_OUTPUT, out_name)\n",
    "\n",
    "        # Frame pattern\n",
    "        frame_pattern = os.path.join(frames_out, 'frame_%08d_out.png')\n",
    "        test_frame = os.path.join(frames_out, 'frame_00000001_out.png')\n",
    "        if not os.path.exists(test_frame):\n",
    "            samples = sorted(glob.glob(os.path.join(frames_out, '*.png')))\n",
    "            if samples:\n",
    "                first = os.path.basename(samples[0])\n",
    "                log(task_id, f'  Pattern fallback: {first}')\n",
    "                import re as _re\n",
    "                match = _re.search(r'(\\d{6,})', first)\n",
    "                if match:\n",
    "                    num_str = match.group(1)\n",
    "                    fmt_str = f'%0{len(num_str)}d'\n",
    "                    frame_pattern = os.path.join(frames_out, first.replace(num_str, fmt_str))\n",
    "\n",
    "        log(task_id, f'  Frame pattern: {os.path.basename(frame_pattern)}')\n",
    "\n",
    "        # Build FFmpeg cmd with max threads for fast PNG decoding\n",
    "        input_fps = str(int(round(source_fps)))\n",
    "        ff = ['ffmpeg', '-y', '-threads', '0',\n",
    "              '-framerate', input_fps, '-i', frame_pattern]\n",
    "        if has_audio and not mute_audio:\n",
    "            ff.extend(['-i', input_path, '-map', '0:v', '-map', '1:a?'])\n",
    "\n",
    "        # FPS: framerate filter (fast) instead of minterpolate (slow)\n",
    "        if need_interpolation:\n",
    "            fps_ratio = effective_fps / max(source_fps, 1)\n",
    "            if fps_ratio >= 1.8:\n",
    "                log(task_id, f'  Interpolating {source_fps:.0f} -> {effective_fps} FPS')\n",
    "                ff.extend(['-vf', f'framerate=fps={effective_fps}:interp_start=0:interp_end=255:scene=100'])\n",
    "            else:\n",
    "                log(task_id, f'  Adjusting {source_fps:.0f} -> {effective_fps} FPS')\n",
    "                ff.extend(['-vf', f'fps={effective_fps}'])\n",
    "\n",
    "        # Select encoder (auto-detects resolution limit)\n",
    "        enc_args, encoder_label = select_encoder(out_w, out_h)\n",
    "        log(task_id, f'  Encoder: {encoder_label}')\n",
    "        if out_w > NVENC_MAX_DIM or out_h > NVENC_MAX_DIM:\n",
    "            log(task_id, f'  [INFO] {out_w}x{out_h} exceeds NVENC limit, using CPU encoder')\n",
    "        ff.extend(enc_args)\n",
    "\n",
    "        if has_audio and not mute_audio:\n",
    "            ff.extend(['-c:a', 'aac', '-b:a', '320k'])\n",
    "        ff.extend(['-r', str(effective_fps)])\n",
    "        ff.extend(['-movflags', '+faststart', out_path])\n",
    "        log(task_id, f'  Encoding video...')\n",
    "        update_status(task_id, 'merging', 80, f'Encoding with {encoder_label}...')\n",
    "\n",
    "        t3 = time.time()\n",
    "        ff_output_lines = []\n",
    "        fp = subprocess.Popen(ff, stdout=subprocess.PIPE, stderr=subprocess.STDOUT,\n",
    "                              universal_newlines=True, bufsize=1)\n",
    "        for line in iter(fp.stdout.readline, ''):\n",
    "            ff_output_lines.append(line.strip())\n",
    "            frame_match = re.search(r'frame=\\s*(\\d+)', line)\n",
    "            if frame_match and total_frames > 0:\n",
    "                cf = int(frame_match.group(1))\n",
    "                pct = min(80 + int((cf/total_frames)*18), 98)\n",
    "                stage_msg = f'Encoding frame {cf}/{total_frames}'\n",
    "                update_status(task_id, 'merging', pct, stage_msg)\n",
    "                task_logs[task_id] = [l for l in task_logs[task_id] if not l.startswith('  Encoding frame ')]\n",
    "                task_logs[task_id].append(f'  Encoding frame {cf}/{total_frames}')\n",
    "        fp.wait()\n",
    "        encode_time = time.time() - t3\n",
    "\n",
    "        if fp.returncode != 0:\n",
    "            err_tail = '\\n'.join(ff_output_lines[-5:])\n",
    "            log(task_id, f'  FFmpeg ERROR: {err_tail}')\n",
    "            raise Exception(f'FFmpeg failed (rc={fp.returncode}): {err_tail[:300]}')\n",
    "        if not os.path.exists(out_path):\n",
    "            raise Exception('Output file not created')\n",
    "\n",
    "        out_mb = os.path.getsize(out_path) / (1024*1024)\n",
    "        log(task_id, f'\\u2713 PHASE 3 COMPLETE: Encoded in {encode_time:.1f}s')\n",
    "        log(task_id, f'\\u2713 Output: {out_name} ({out_mb:.1f} MB)')\n",
    "\n",
    "        total_time = time.time() - t0\n",
    "        log(task_id, '')\n",
    "        log(task_id, f'\\u2705 ALL DONE in {total_time:.1f}s!')\n",
    "        log(task_id, f'  {width}x{height} -> {out_w}x{out_h} | {out_mb:.1f} MB')\n",
    "        update_status(task_id, 'completed', 100, f'Complete! ({out_mb:.1f} MB)')\n",
    "        print(f'\\n[DONE] {out_name} ({out_mb:.1f} MB) in {total_time:.1f}s')\n",
    "\n",
    "    except Exception as e:\n",
    "        _upscale_running = False\n",
    "        log(task_id, f'\\u274c ERROR: {str(e)[:150]}')\n",
    "        update_status(task_id, 'failed', 0, f'Error: {str(e)[:150]}', str(e))\n",
    "        print(f'[FAIL] {task_id}: {e}')\n",
    "        traceback.print_exc()\n",
    "    finally:\n",
    "        _upscale_running = False\n",
    "        if os.path.exists(work_dir):\n",
    "            shutil.rmtree(work_dir, ignore_errors=True)\n",
    "        if os.path.exists(input_path):\n",
    "            try: os.remove(input_path)\n",
    "            except: pass\n",
    "        job_path = os.path.join(DRIVE_JOBS, f'{task_id}.json')\n",
    "        try:\n",
    "            if os.path.exists(job_path): os.remove(job_path)\n",
    "        except: pass\n",
    "\n",
    "\n",
    "def _refresh_drive_cache(folder):\n",
    "    \"\"\"Force Google Drive FUSE to refresh directory listing.\n",
    "    Write+delete a tiny temp file to invalidate the cache.\"\"\"\n",
    "    try:\n",
    "        probe = os.path.join(folder, '.probe')\n",
    "        with open(probe, 'w') as f: f.write('x')\n",
    "        os.remove(probe)\n",
    "    except: pass\n",
    "\n",
    "\n",
    "def watch_jobs():\n",
    "    print()\n",
    "    print('=' * 55)\n",
    "    print('  RZ UPSCALER - JOB WATCHER RUNNING')\n",
    "    print(f'  GPU: {GPU_INFO[\"name\"]} ({GPU_INFO[\"memory\"]})')\n",
    "    print(f'  Models: animevideov3, x4plus')\n",
    "    print(f'  Supports: Video + Image')\n",
    "    print(f'  Watching: {DRIVE_JOBS}')\n",
    "    print('  Waiting for jobs from desktop app...')\n",
    "    print('=' * 55)\n",
    "    print()\n",
    "\n",
    "    poll_count = 0\n",
    "    while True:\n",
    "        try:\n",
    "            # Force-refresh Drive FUSE cache before scanning\n",
    "            _refresh_drive_cache(DRIVE_JOBS)\n",
    "\n",
    "            # Use os.listdir (more reliable than glob for FUSE)\n",
    "            raw_files = os.listdir(DRIVE_JOBS)\n",
    "            job_files = sorted([f for f in raw_files if f.endswith('.json') and not f.endswith('.tmp')])\n",
    "\n",
    "            poll_count += 1\n",
    "            if poll_count % 12 == 1:  # Log every ~60s\n",
    "                print(f'[POLL #{poll_count}] Files in Jobs/: {raw_files if raw_files else \"(empty)\"}')\n",
    "\n",
    "            for job_name in job_files:\n",
    "                task_id = job_name.replace('.json', '')\n",
    "                if task_id in processed_jobs: continue\n",
    "\n",
    "                job_path = os.path.join(DRIVE_JOBS, job_name)\n",
    "                try:\n",
    "                    with open(job_path, 'r') as f:\n",
    "                        job = json.load(f)\n",
    "                except (json.JSONDecodeError, OSError):\n",
    "                    continue\n",
    "\n",
    "                filename = job.get('filename', '?')\n",
    "                model_name = job.get('model', 'realesr-animevideov3')\n",
    "                scale = job.get('scale', 4)\n",
    "                file_type = 'IMAGE' if is_image_file(filename) else 'VIDEO'\n",
    "                print(f'\\n[NEW JOB] {task_id}: {filename} ({file_type}, model={model_name}, {scale}x)')\n",
    "                processed_jobs.add(task_id)\n",
    "\n",
    "                # Route to image or video processor\n",
    "                if is_image_file(filename):\n",
    "                    process_image(job)\n",
    "                else:\n",
    "                    process_video(job)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f'[ERROR] Job watcher: {e}')\n",
    "            traceback.print_exc()\n",
    "\n",
    "        time.sleep(5)\n",
    "\n",
    "watch_jobs()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbformat_minor": 2,
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}